---
title: "Data Analysis 3 - Pattern Discovery and Regression Analysis 2017/2018 Fall"
author:
- name: Peter Paziczki
- name: Imre Boda
- name: Balazs Zankay
date: '2017 november 28'
output:
  html_document: default
  pdf_document: default
  word_document: default
---

<style>
body {
text-align: justify}
</style>

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r load}
library(data.table)
library(ggplot2)
library(lspline)
library(pander)

#presentation parameters
theme_update(plot.title = element_text(hjust = 0.5, size = 12))

#Reading input files
GDP <- fread('GDP_per_capita_2014-Data.csv', encoding = 'UTF-8')
Life <- fread('Life_expectancy_at_birth_2014-Data.csv', encoding = 'UTF-8')
#Reading file to compare entries against country list
CountryList <- read.csv('https://www.searchify.ca/wp-content/uploads/2016/09/country-keyword-list.csv',fileEncoding="UTF-16LE")
```

# DA3 Assignment #2

## Problem2.1


### <span style="color:blue">Download cross-country data on life expectancy and GDP per capita. 
- “GDP per capita, PPP (constant)” and “Life expectancy at birth (total)”
</span>

We have downloaded both the above mentioned indicators for 2014, storing them in two separate csv files, GDP_per_capita_2014-Data.csv and Life_expectancy_at_birth_2014-Data.csv.

### <span style="color:blue"> Q1. 1. Delete unnecessary columns and save a csv file with three columns only: country name, life expectancy and GDP per capita. Keep countries with non-missing values for life expectancy and GDP per capita. Document what you do.
</span>

```{r Q1_basic}
# Joining the two tables by Country name column.

# Settin the ON clause as keys of the tables:
setkey(GDP, `Country Name`)
setkey(Life, `Country Name`)
# Inner joining the two tables, DT syntax
Data_raw <- Life[GDP, nomatch=0]

# Dropping the unnecessary columns, keeping only country name, life expectancy and GDP per capita columns
Data <- Data_raw[, -c(1,2,4,6:8)]
# renaming country name, life expectancy and GDP per capita columns for easier usage
names(Data) <- c("country", "life", "GDP")

# Dropping the observations where there is no country, and dropping countries where life expectancy and/or GPD are missing
Data <- Data[country!="",]
Data <- Data[life!="..", ]
Data <- Data[GDP!="..", ]
n <- Data_raw[`Country Name` != "",.N] # number of countries in the original data set
n_country <- nrow(CountryList)

# Both life expectancy and GDP per capita are character variables, they need to be converted into numeric variables.
Data <- Data[, lapply(.SD, as.numeric), by = country, .SDcols = c('life', 'GDP')]

# Shaping data
Data [, "GDP"] <- Data [, .(GDP = GDP/1000)]
# Taking the log of GDP per capita and sroting it in logGDP column.
Data [, logGDP := log(GDP)]
```

#### Data preparation and Cleaning

We have loaded both csv files and merged them with inner join. By using this special command we could make sure that relevant columns (Life expectancy and GDP) from the two tables were merged by matching the country name column, so the right values have been paired. The countries with missing life expectancy and GDP values have been dropped. We have `r Data[,.N]` entries of the `r n` left to analyze. Other unnecessary columns have also been dropped, such as Series Name, Series Code, Country Code. We have renamed the remaining columns as *country*, *life* and *GDP*, so it will be easier to type and use them. Life expectancy at birth is measure of how long people people live on average in a specific country. GDP per capita stands for gross domestic product at purchasing power parity of a specific country, both at 2014 in our case. Finally we have divided GDP per capita by 1000 and took the log of it because GPD per capita makes more sense in relative than in absolute terms, we will investigate it further in the next exercise.

We have downloaded a csv file containing the list of `r n_country` countries in the world as of now. There were many entries in our data set that were not about countries but some aggregations, so they were dropped.
We have aggregated lines in the data, that we have to remove as we only care about countries in the analysis.
We do this cleaning in two steps: first we check entries where the "country" is not inlcuded in the list of downloaded countries.
Then we manually checked all of them, and collected those that are really not countries. (In the previous step some get classified as "non country" due to different writing in Data Bank and in the downloaded country list csv file). Once we had this collection of real non-countries, we removed all from the Data.

```{r Q1_Cleaning, results='hide'}
#there were countries where a country had different name in the original data and in the country list we have downloaded.
SuspectedGarbage <- Data[!country %in% CountryList[,1]]
Garbage <- SuspectedGarbage [ -c(1,2,4,5,6,7,8,11:15,20,21,28,29,32,38,39,40,41,50,51,52,61,64,65,66,68,71,75,76,77,80),]
#let's check that we put non-countries to garbage and we kept only countries
Garbage [, country]
SuspectedGarbage [ c(1,2,4,5,6,7,8,11:15,20,21,28,29,32,38,39,40,41,50,51,52,61,64,65,66,68,71,75,76,77,80),country]
#Removing all non country entries from the database and keeping only countries
Data <- Data[!country %in% Garbage [,country]]

# creating a csv 
Data_to_csv <- Data
Data_to_csv$logGDP <- NULL
write.csv(Data_to_csv, file = "dataset_for_2.1.csv")
```

The `r Garbage[,.N]` entries have been dropped because of being marked as non-countries. After data cleaning we have `r Data[,.N]` countries to investigate.

Please find summary statistics of life variable below:

```{r Q1_LifeSummary}
pander(summary(Data[,life]))
ggplot (Data, aes(life)) + geom_histogram(binwidth = 1) + ggtitle(labs(title = "Q1. Histogram of life variable", x = "Life expectancy at birth [years]"))
```

```{r Q1_min_max_life_countries}
pander(Data [life == Data [,min(life)] | life == Data [,max(life)],])
```

Life expactancy is the highest in Hong Kong SAR, China, and the lowest in the Central African Republic, `r round(max(Data$life),2)` and `r round(min(Data$life),2)` respectively. The difference between the minimum and maximum values is quite large. Mean is close to the median, but life expectancy variable does not have a symmetric distribution, it rather seems to be skewed to the left.

Please find summary statistics of GDP per capita variable below:

```{r Q1_GDPSummary}
pander(summary(Data[,GDP]))
ggplot (Data, aes(GDP)) + geom_histogram ( binwidth=6) + ggtitle(labs(title = "Q1. Histogram of GDP variable", x = "GDP per capita [1000 USD]"))
```

Countries with minimuma and maximum GDP are the followings:
```{r Q1_min_max_GDP_countries}
pander(Data [GDP == Data [,min(GDP)] | GDP == Data [,max(GDP)],])
```

GDP follows a log normal like distribution with a long right tail, it is tipically a clear sign that we are better to take the logarithm of the variable. GDP is the highest in Macao SAR, China, and the lowest in the Central African Republic, `r round(max(Data$GDP),2)` and `r round(min(Data$GDP),2)` respectively. In this case the difference between the minimum and maximum value is very large.

Please find summary statistics of logGDP variable below:

```{r Q1_logGDP}
pander(summary(Data[,logGDP]))
ggplot(Data, aes(logGDP)) + geom_histogram (binwidth=0.5) + ggtitle(labs(title = "Q1. Histogram of logGDP variable", x = "Log GDP per capita [1000 USD]"))
```

The histogram of logGDP per capita has a more symmetric distribution then the GDP per capita variable. The spread is also big in this case.

### <span style="color:blue"> Q2. Estimate a lowess regression of life expectancy on ln gdp per capita. Estimate a linear regression of life expectancy on GDP per capita that best captures the nonlinearity you found (life expectancy on a piecewise linear spline or a polynomial in the explanatory variable). Argue for your choice. Report the coefficient estimates as well as their confidence interval, interpret and visualize the results.
</span>

In the following sections we go deeper in understanding our data.

First, let's have a look at the scatterplot with GDP per capita on the x axis and life expectancy at birth on the y axis.

```{r Q2_scatterplot_GDP}
# Creating a scatterplot to have a quick look at the data we have:
ggplot(Data, aes(x = GDP, y = life)) + geom_point() +
  ggtitle ("Q2. GDP - Life expectancy") + labs(x="GDP per capita, PPP [USD]",y="Life expectancy at birth [years]")
```

Many countries have a low level of GDP per capita, thus there are many observations close to the y axis. As we stated above, GDP per capita is strongly skewed to the right, having logGDP on the x axis might give a fit.

```{r Q2_scatterplot_logGDP}
ggplot(Data, aes(x = logGDP, y = life)) + geom_point () +
  ggtitle ("Q2. Log GDP - Life expectancy") + labs(x="Log GDP per capita, PPP [USD]",y="Life expectancy at birth [years]")
```

We took the log of GDP per capita, as we are interested in relative % changes instead of absolute terms. Lowess produces a smooth curve, that allows us to capture non-linear patterns. (The con of lowess is that it does not provide a formula to describe the relationship between life expectancy and GDP. What lowess does is that it provides an expected y value for every x values and for x values in-between resulting in a graph that we can use in qualitative analysis.
In this particular case we have log GDP per capita on the x axis and life expectancy on the y axis.

```{r Q2_lowessGraph}
# Estimating a lowess non-parametric regression on the data set.
reg_loess <- loess (life ~ logGDP, Data)
ggplot(data = Data, aes(x=logGDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Lowess regression") + labs(x="Log GDP per capita, PPP [USD]",y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_loess)),colour="blue",size = 1)
summary (reg_loess)
```

We can see that the graph has a positive slope in general. At the right end of the curve it gets a little flatter, but remains still positive. So we can assumte that there is some sort of positive correlation between these two variables. A possible interpretation at this point can be that there is a general positive relationship between GDP per capita and life expectancy. The higher the GDP per capita is in a country, the longer the life expectancy is on average.

#### Level - Log Linear Regression
``` {r Q2_LevLogRegression}
reg_levlog <- lm(life ~ logGDP, data=Data)

#ggplot (Data, aes (x=logGDP, y = life )) + geom_point (size = 1.5) + 
#ggtitle("Q2. Level - Log linear regression") + labs(x = "Log GDP per capita [1000 USD]", y = "Life Expectancy [year]") + 
#geom_smooth (method = "lm")

ggplot (Data, aes (x=logGDP, y = life )) + geom_point (size = 1.5) + 
ggtitle("Q2. Level - Log linear Regression") + labs(x = "Log GDP per capita [1000 USD]", y = "Life Expectancy [year]") + 
geom_line(data=Data,aes(x=logGDP,y=predict(reg_levlog)),colour="blue",size = 1) + geom_smooth(method = 'lm')

summary (reg_levlog)
Data[,res_reg_levlog := residuals(reg_levlog)]
```

We seem to have rather small residual errors and pretty good R-squared, 66.5%, confirming the relationship between logGDP and Life Expectancy.
The intercept estimate is 58.98, which is hard to interpret in real life for practical reasons, it means that in a country with 0 logGDP the life expectancy at birth would be approx. 59 years on average. The slope estimate is 5.46, which means that life expectancy is 0.546 years higher on average in countries with 10% higher GDP per capita. The slope estimate is significant at 0.1%, with other words, life expectancy and log GDP per capita are correlated at a 99.9%.

Equatorial Guinea has the greatest negative residual, the life expectancy is `r round(abs(min(residuals(reg_levlog))),2)` lower that one could expect based on the regression. The next two countries with greatest negative residuals are Nigeria and Swaziland, -15.9 and -14.3 years respectively. The highest positive residuals are Vietnam, Solomin Islands and Nicaragua, the residuals are over 7 years, meaning that people live more than 7 years longer on average, as one could expect based on the GDP per capita.

The residuals of the seven countries with highest GDP per capita are all negative, which is quite unexpected. This is something that we are going to consider when creating piecewise linear splines.


#### Log - Log regression
``` {r Q2_Log-Log}
# LOG-LOG REGRESSION
reg_loglog <- lm(log(life) ~ logGDP, data=Data)
ggplot(data = Data, aes(x=logGDP, y=log(life))) +  geom_point(size=1.5) +
  ggtitle ("Q2. Log-Log linear regression") +  
  labs(x="Log - GDP per capita, PPP [USD]", y="Log - Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_loglog)),colour="blue",size = 1) + geom_smooth(method = 'lm')
summary(reg_loglog)
```  

R-squared is slightly lower than in the previous case, but it is not significant at all. Also, this regression is more difficult to interpret. It can be interpreted as life expectency is 0.078% higher on average for observations with 1% higher GDP per capita. 


#### Lev - Lev regression

Though the scatterplots above suggested that the level - level linear correlation probaly is not the best model, just for the sake of completeness let's see a level-level linear regression model.

``` {r Q2_Lev-Lev}
# LOG-LOG REGRESSION
reg_levlev <- lm(life ~ GDP, data=Data)
ggplot(data = Data, aes(x=GDP, y=life)) +  geom_point(size=1.5) +
  ggtitle ("Q2. Level - Level linear regression") +  
  labs(x="GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=GDP,y=predict(reg_levlev)),colour="blue",size = 1) + geom_smooth(method = 'lm')
summary(reg_levlev)
```  

Both R-squared and the plot confirms our assumption that there are much better models that the simple level - level linear regression. This plot could obviously not capture the relationship as good as the previous ones.


#### Level - Level Quadratic regression

``` {r Q2_Level-Level_QuadraticRegression}
# Estimating a quadratic regression on GDP and life expectancy:
Data[, GDP_sq := GDP^2]
reg_quad_levlev <- lm(life ~ GDP + GDP_sq, data=Data)

ggplot(Data, aes(x=GDP, y=life)) +  geom_point(size=1.5) + 
  ggtitle ("Q2. Quadratic regression") +  
  labs(x="GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=GDP,y=predict(reg_quad_levlev)),colour="blue",size = 1)

summary(reg_quad_levlev)
```

R-squared is lower and residual error is higher than before, indicating that it might not be as good model as the previous one. Frankly, probably there is nothing to justify that life expectancy would peek at `r round (0.58 / 2 / 0.0039)` kUSD GDP per capita, and very rich countries would suffer. The reasonably small error rate to this model is likely attributable to the fact that we have very few very rich countries (hence, small number of observations on this end.)


#### Level - Log Quadratic regression
``` {r Q2_Level_Log_QuadraticRegression}
# Estimating a quadratic regression on log GDP pre capita and life expectancy:
Data[, logGDP_sq := logGDP^2]
reg_quad_levlog <- lm(life ~ logGDP + logGDP_sq, data=Data)

ggplot(Data, aes(x=logGDP, y=life)) +  geom_point(size=1.5) + 
  ggtitle ("Q2. Quadratic regression") +  
  labs(x="log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_quad_levlog)),colour="blue",size = 1)

summary(reg_quad_levlog)
```


#### Level - Level Cubic Regression
``` {r Q2_Level_Level_CubicRegression}
Data[,GDP_cu := GDP^3]
reg_cub_levlev <- lm(life ~ GDP + GDP_sq + GDP_cu, data=Data)

ggplot(data = Data, aes(x=GDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Cubic regression") +  
  labs(x="GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=GDP,y=predict(reg_cub_levlev)),colour="blue",size = 1)

summary(reg_cub_levlev)
```


#### Level - Log Cubic Regression
``` {r Q2_Level_Log_CubicRegression}
Data[,logGDP_cu := logGDP^3]
reg_cub_levlog <- lm(life ~ logGDP + logGDP_sq + logGDP_cu, data=Data)

ggplot(data = Data, aes(x=logGDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Cubic regression") +  
  labs(x="log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_cub_levlog)),colour="blue",size = 1)

summary(reg_cub_levlog)
```


#### Piecewise Linear Spline

In the lowess diagram we have seen that the slope is changing at about x = 4. This is confirmed by our finding at the log-level regression where we uncovered that the seven countries with highest GDP per capita all have negative residuals (i.e. in all these super-rich countries life expectancy was below the linear regression line). We selected the knot accordingly and build the PLS model.

``` {r Q2_PLS}

# PIECEWISE LINEAR SPLINE IN LEVEL-LOG REGRESSION
knots <- c(4)
reg_PLS <- lm(life ~ lspline(logGDP,knots), data=Data)

ggplot(data = Data, aes(x=logGDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Piecewise Linear Spline") +
  labs(x="Log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_PLS)),colour="blue",size = 1) +
  geom_vline(xintercept =knots,colour="red")

summary (reg_PLS)
```

The R-squared of the regression is 67.28%. It is bit higher than the R-squared of the level log regression. It is not surprising because with two lines with possibly two different slopes we have to provide at least as good fit as with one linear. The slope of the first linear is 5.67, shows positive relation between log GDP per capita and life expectancy, and it is significant at 0.1%. A slope of 5.67 means, that below approximately 54,600 USD (log GDP per capita = 4) the life expectancy is 0.567 years higher on average for countries with 10% higher GDP erp capita. The second linear beyond log GDP per capita 4 has a negative slope and it has captured that we have observed when doing a lowess regression. The slope estimate is -1.66, but it is not significant at even 10%. This second short linear provides a better fit for 9 countries, meaning that the life expectancy is 0.166 years lower on average in countries with 10% higher GDP per capita.


#### Choosing the best model and evaluating it

After the investigation we can see that the level - log regression has best captured the relation between life expectancy and GDP per capita, with logarithm of GDP PPP as the explanatory variable.

```{r Q2_Model selection}

RSq <- data.table (c("Level - Log  :  ",
                     "Log - Log    :  ", 
                     "Level - Level:  ", 
                     "Quadratic Level - Level   :  ", 
                     "Quadratic Level -Log",
                     "Cubic Level - Level        :  ", 
                     "Cubic Level - Log        :  ", 
                     "PLS (spline) :  "), 
                   c(summary(reg_levlog)$r.squared,
                     summary(reg_loglog)$r.squared,
                     summary(reg_levlev)$r.squared,
                     summary(reg_quad_levlev)$r.squared,
                     summary(reg_quad_levlog)$r.squared,
                     summary(reg_cub_levlev)$r.squared,
                     summary(reg_cub_levlog)$r.squared,
                     summary(reg_PLS)$r.squared
                     ))
pander(RSq)
```

Quadratic and cubic polynomial regression also captured that change in the slope for countries with the highest GDP per capita, but level - log regression and linear spline were the ones that best captured the variance in y.

``` {r Q2_Coefficients,for studying purposes, results='hide'}
# Coefficient calculations, confidence interval
# for studying purposes we were computing it by hand as well

### x = logGDP, y = life

## easy way:
coef (reg_levlog)
confint (reg_levlog)

## manual
Beta_estimate <- cov (Data [,logGDP], Data[,life]) / var (Data [, logGDP]) # cov (x,y) / var (x)
Alpha_estimate <- Data [, mean(life)] - Beta_estimate * Data [,mean (logGDP)]  # mean (y) - beta * mean (x)
Beta_estimate
Alpha_estimate
# sd of Residual Error calculation in 3 ways
sdResidErr1 <- sd (Data [, life - (Alpha_estimate + Beta_estimate * logGDP)]) #R built in sd function
sdResidErr2 <- Data [, (sum((life - (Alpha_estimate + Beta_estimate * logGDP))^2) / (.N-1))^0.5] #formula, n-1
sdResidErr3 <- Data [, (sum((life - (Alpha_estimate + Beta_estimate * logGDP))^2) / (.N-2))^0.5] #formula, n-2

sdResidErr1
sdResidErr2
sdResidErr3
# interpretation: sdResidErr1 and sdResidErr2 are the same, but different from tha value that we saw in summary (reg_levlog) above. The reason is that summary (reg_levlog) calculated with df = N-2, as it was also mentioned in that printout. In the below confidence interval calculation we will use sdResidErr1
Conf95 <- c(Beta_estimate - 1.96 * sdResidErr1 / Data [,sd(logGDP)]  / (nrow (Data)-1) ^0.5, Beta_estimate + 1.96 * sdResidErr1 / Data [,sd(logGDP)]  / (nrow (Data) -1) ^0.5)
Conf95

# Coefficients and Confidence interval at 95% have been calculated with built-in R functions as well as with statistical formulas. It is worth noting that Alpha and Beta estimates are the same that we got earlier, and examined when printed the summary of reg_levlog model.
```

Confidence interval (CI) of the predicted value tells us where to expect average y given the value of x in the population represented by the data.
In the below two charts we put up the 95% mean and confidence intervales for lowess - linear (level - log) and lowess - PLS regressions.
The reason why we selected lowess as a comparison base is that it is supposed to be the closest fit.

```{r Q2_interpreting_visualizing}
plx_lowess <- predict (reg_loess, se = T)
plx_levlog <- predict (reg_levlog, se = T)
plx_PLS <- predict (reg_PLS, se = T)


ggplot(data = Data, aes(x=logGDP, y=life)) +
  ggtitle ("Q2. Lowess and Linear with Confidence intervals at 95%") + labs(x="Log GDP per capita, PPP [USD]",y="Life expectancy at birth [years]") +
  geom_line(data=Data, aes(x=logGDP,y=plx_lowess$fit),colour="blue",size = 1) + 
  geom_line(data=Data, aes(x = logGDP, y = plx_lowess$fit - qt(0.975, plx_lowess$df)*plx_lowess$se), lty = 2, colour="blue") + 
  geom_line(data=Data, aes(x = logGDP, y = plx_lowess$fit + qt(0.975, plx_lowess$df)*plx_lowess$se), lty = 2, colour="blue") +
  geom_line(data=Data,aes(x=logGDP,y=plx_levlog$fit),colour="red",size = 1)+
  geom_line(data=Data, aes(x = logGDP, y = plx_levlog$fit - qt(0.975, plx_levlog$df)*plx_levlog$se), lty = 4, colour="red") +
  geom_line(data=Data, aes(x = logGDP, y = plx_levlog$fit + qt(0.975, plx_levlog$df)*plx_levlog$se), lty = 4, colour="red") +
  theme(panel.background = element_blank())
  
ggplot(data = Data, aes(x=logGDP, y=life)) +
  ggtitle ("Q2. Lowess and PLS with Confidence intervals at 95%") + labs(x="Log GDP per capita, PPP [USD]",y="Life expectancy at birth [years]") +
  geom_line(data=Data, aes(x=logGDP,y=plx_lowess$fit),colour="blue",size = 1) + 
  geom_line(data=Data, aes(x = logGDP, y = plx_lowess$fit - qt(0.975, plx_lowess$df)*plx_lowess$se), lty = 2, colour="blue") + 
  geom_line(data=Data, aes(x = logGDP, y = plx_lowess$fit + qt(0.975, plx_lowess$df)*plx_lowess$se), lty = 2, colour="blue") +
  geom_line(data=Data,aes(x=logGDP,y=plx_PLS$fit),colour="red",size = 1) + 
  geom_line(data=Data, aes(x = logGDP, y = plx_PLS$fit - qt(0.975, plx_PLS$df)*plx_PLS$se), lty = 4, colour="red") +
  geom_line(data=Data, aes(x = logGDP, y = plx_PLS$fit + qt(0.975, plx_PLS$df)*plx_PLS$se), lty = 4, colour="red") +
  theme(panel.background = element_blank())
```

### <span style="color:blue"> 3. Estimate a weighted regression (weight=population). Compare results to what we saw in class. 
</span>

In order to do it, first we need to enhance our data with population. For that we downloaded 2014 population data form the same "World Development Indicators" website.

``` {r Q3_Population, results='hide'}
## Download and clean population data
PopData <- fread ('Population_2014.csv')
str (PopData)
PopData <- PopData [PopData [[2]] == "SP.POP.TOTL"]   #filtering to Total Population only (where data in column 2 = "SP.POP.TOTL")
PopData <- PopData [, -c(1,2,4)]
names(PopData) <- c("Country", "Population")
PopData <- PopData [, .(Population = as.numeric(Population)), by = Country]
PopData <- PopData [!is.na(Population),]
str (PopData)

## Enhance Data with population info
setkey(PopData, `Country`)
setkey(Data, `country`)
Data2 <- Data[PopData, nomatch=0] #inner join DT syntax
str (Data2)
# sanity check (values)
Data2 [is.na(Population),]
Data2 [country == "Hungary",]
Data2 [country == "United States",]
# Cool, we got data filled in for all
```

``` {r Q3_weighted model}
reg_weight<- lm (life ~ logGDP, weight = Population, data = Data2)

ggplot (Data2, aes (x = logGDP, y = life, size = Population)) + 
  geom_point(shape = 21, fill = "#009E73", alpha = 0.5, show.legend = FALSE) + 
  scale_size_continuous(range = c(1, 15)) +
  ggtitle ("Q3. Weighted Lev-Log Regression") +
  labs(x="Log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_weight)),colour="blue",size = 1)

summary (reg_weight)
```

When doing a level-log regression without considering the population, the slope estimate was 5.46. It is now 5.82, slightly higher. China and India have the highest population in the world and they are very close to the regression line and are approximately in the middle of the log GDP per capita distribution, hence they don't alter the slope significantly. We can say that after considering the population as weight, life expectancy is 0.582 years higher on average in countries with 10% higher GDP per capita.


##<span style="color:blue"> Problem 2.2

Download hotels_all_nov21.csv. Pick a city. Consider hotels and hostels. Consider all with at least 2 stars. You have 6 tasks (1p each). 
The goal of the exercise is to use information you have in your data to find a shortlist of five hotels and/or hostels that are good candidates for a good deal. You have to estimate a regression of prices (or log prices) on the other variables of your choice. You have to document your analysis and print the shortlist. 
</span>

``` {r Q22_basic, results='hide'}
library(lmtest)
library(stargazer)
library(sandwich)

#### Data Loading
file <- 'hotels_all_nov21.csv'
# exercise parameters
MIN_STARS <-2
hotels_all <- fread(file, encoding = 'UTF-8')
str (hotels_all)

#### Selecting a city randomly
citycount <- length(hotels_all [, unique(city)])
set.seed (28)
selectindex <- round(runif (1, min =1, max = citycount),0)
mycity <- hotels_all [, unique(city)][selectindex]
mycity

#### Filtering to Accomodation type and star
#checking if accomodation types are various spellings of "hotel" and "hostel" in the dataset
hotels_all [city == mycity & stars >=MIN_STARS, unique (accommodation_type)]
#filtering to selected city and requested star and accomodation types
myhotels <- hotels_all [city == mycity & stars >=MIN_STARS & accommodation_type %in% c("Hotel", "Hostel"),]
# str (myhotels)

#### Data Cleaning 1: dropping those with missing parameters
myhotels [is.na (distance) | is.na(price) | is.na(stars) | is.na(rating) | is.na(badge_excellence) | is.na(rating_reviewcount),]
data_missing <- myhotels [is.na (distance) | is.na(price) | is.na(stars) | is.na(rating) | is.na(badge_excellence) | is.na(rating_reviewcount),.N]
myhotels <- myhotels [!(is.na (distance) | is.na(price) | is.na(stars) | is.na(rating) | is.na(badge_excellence) | is.na(rating_reviewcount)),]

#### Data Cleaning 2: dropping duplicates
# looking for duplicates in some ways (ID, name, address)
myhotels [,.N] - myhotels [,length(unique (address))]
myhotels [, .N] - myhotels [,length(unique (name)) ] 
# showing the duplicates
myhotels [,.(name, .N), by = id][N>1,]
myhotels [,.(name, .N), by = address][N>1,]
myhotels [,.(address, .N), by = name][N>1,]
# checking the other 2 on the list with identical names & addresses
myhotels [name %in% c("Athens Lotus Hotel", "Metropolitan Hotel")]
myhotels1 <- myhotels[!duplicated(myhotels[,id]),]
n_duplicate <- myhotels[duplicated(myhotels[,id]),.N]
```

First we have loaded the file and picked a city randomly (happened to be Athens). We have filtered down the data to accommodation types 'Hostel' and 'Hotel' with at least 2 stars. After narrowing down the data we have done further data cleaning. We are interested in a few variables, such as distance from the city center, price, number of stars, rating, rating viewcounts, different badges of excellence the hotel or hostel might have, all other variables are excluded. First we have dropped `r data_missing` observations that miss parameters we might be interested in. Then we have dropped `r n_duplicate` duplicates, there were hotels with the same address, and a few hotels had more addresses, these have been sorted out.

``` {r Q22_extremevalues, results='hide'}
max_in <- myhotels1 [city_actual == "Piraeus", max (distance)]
myhotels2 <- myhotels1[distance <= max_in, ]
myhotels2 [price >200,]  #checking who the very expensive ones are. After analyzing on web, we found tht these all are "normal" high priced hotels, we keep those.
myhotels3 <- myhotels2 [, .(distance, stars, badge_excellence, rating, rating_reviewcount, price)] #remove not needed data
```

Next step was to filter extreme values, a few hotels have been removed because being considered to be outside of Athens (apparently all those that are further away than the hotel with the highest distance in Piraeuswhich means that we conside everything that is further away then Piraeus as suburb not Athens). It is important to mention that we did not drop any hotel due to high price.
We limited our investigation to hotels and hostels that are not futher than `r max_in`km.

### <span style="color:blue"> 2.2.1. Pick a set of variables. Describe all variables used in the analysis.
</span>

Now we need to describe all the variables we are going to use in the analysis.

First variable to discuss is price, currency is EUR and tells us, how much a single night costs for 2 people in that certain accommodation.

```{r Q221_statistics_of_price}
# SUMMARY STATISTICS ON PRICE
qplot(myhotels3[,price], geom="histogram", binwidth=20) + theme_bw() + ggtitle(labs(title = "Q221. Histogram of price variable", x = "Price [EUR]"))
price_stat<-myhotels3[,.(mean_price = mean(price) , sd_price = sd(price), 
                      min_price = min(price) , max_price = max(price), 
                      p50=quantile(price,.50), p95=quantile(price,.95), n=.N )]
pander(price_stat)

myhotels3$lnprice <- log(myhotels3$price)
```

Price variable has a log normal like distribution, it is skewed to the right with a long right tail. The mean is `r price_stat$mean_price` EUR. The most offers are in the 50-70 price range. Price tells us, how much a single night costs for 2 people in that certain accommodation. We took the log of the price variable, please find a histogram of it below.

```{r Q221_statistics_of_lnprice}
ggplot(myhotels3, aes(lnprice)) + geom_histogram() + ggtitle(labs(title = "Q221. Histogram of lnprice variable", x = "lnprice"))
```

With having the logarithm of price variable we now have a more symmetric normal like distribution.

Distance variable describes how far a hotel or hostel is from the city center, it is measured in km.

```{r Q221_statistics_of_distance}
# SUMMARY STATISTICS ON DISTANCE
qplot(myhotels3[,distance], geom="histogram", binwidth=0.4) + theme_bw() + ggtitle(labs(title = "Q221. Histogram of distance variable", x = "Distance from the city center [km]"))

distance_stat <-myhotels3[,.(mean_dist = mean(distance) , sd_dist = sd(distance),
                          min_dist = min(distance) , max_dist = max(distance),
                          p50 = quantile(distance,.50), p95 = quantile(distance,.95), n=.N )]
pander(distance_stat)

myhotels3$lndistance = log(myhotels3$distance+0.1)
```

Distance variable has also a log normal like distribution with a long right tail, most of the the hotels and hostels are in the 0.2-0.6km range.

After having these variables shortly described let's create two scatterplots with distance on the x axis, price and lnprice on the y axis, to see, if there is any general relation to observe betweem tha variables.

```{r Q221_distance_price_scatterplots}
ggplot(myhotels3, aes(x=distance, y=price)) + geom_point(shape = 1) + ggtitle(labs(title = "Q221. Scatterplot of price on distance", x = "Distance from the city center [km]", y = "Price [EUR]"))

ggplot(myhotels3, aes(x=distance, y=lnprice)) + geom_point(shape = 1) + ggtitle(labs(title = "Q221. Scatterplot of lnprice on distance", x = "Distance from the city center [km]", y = "lnrice"))
```

Both scatterplot shows that there is a general negative relation between price and distance closer to the city center, which might not be true for observations further from the center. We need to investigate it further.

Stars variable shows how many stars a hotel or hostel has. There are a few accommodations with half stars. 2 stars are the most common in our data, the more stars the accommodation has, the less observations we have in the data. Please find a histogram of stars below.

```{r Q221_statistics_of_stars}
ggplot(myhotels3, aes(stars)) + geom_histogram() + ggtitle(labs(title = "Q221. Histogram of stars variable", x = "stars"))
pander(table(myhotels3$stars))
```

We have created a histogram of the rating variable, please find some summary statistics below.

```{r Q221_statistics_of_ratings}
ggplot(myhotels3, aes(rating)) + geom_histogram() + ggtitle(labs(title = "Q221. Histogram of rating variable", x = "rating"))

rating_stat <-myhotels3[,.(mean_rating = mean(rating) , sd_rating = sd(rating),
                          min_rating = min(rating) , max_rating = max(rating),
                          p50 = quantile(rating,.50), p95 = quantile(rating,.95), n=.N )]
pander(rating_stat)
```

It has a range of 1 - 4.8, with one decimal. These ratings have been given by previous guests and should represent how satisfied they were with services provided. It is a numeric value and its distribution is skewed to the left, the mean is `r rating_stat$mean_rating`.

### <span style="color:blue"> 2.2.2. Investigate potential nonlinearity of each explanatory variable in simple regressions of the dependent variable. Decide on a parametric functional form for each.

We were investiagting potential non-linearity by using lowess non-parametric regression first. This regression is supposed to uncover potential non-linearities. 

```{r Q223_lowessGraph, results='hide'}
# Estimating a lowess non-parametric regression on the data set.
regQ2_loess <- loess (lnprice ~ distance, myhotels3)
ggplot(data = myhotels3, aes(x=distance, y=lnprice)) +
  geom_point(size=1.5) +
  ggtitle ("Q223. Lowess regression") + labs(x="distance",y="lnprice") +
  geom_line(data=myhotels3,aes(x=distance,y=predict(regQ2_loess)),colour="blue",size = 1)
summary (regQ2_loess)
```

The lowess regression shows that there there a strong negative relation between price and distance very close to the city center, but at about 1km far from the center there is a change in the relation. At approximately 1.5km far from the center the relation becomes negative again, but it is much flatter now than in the first section, at the very end it becomes totally flat. It is important to highlight that there are only a few observation in the 2-4 km range.

Amiket szerintem érdemes megnézni:
lev-lev
lev-log
quadratic
cubic

``` {r Q222_nonlinears, results='hide'}
### Creating binary variables out of of badge_excellence
myhotels3 [, Gold := (badge_excellence == "Gold Award 2017") + 0.1]
myhotels3 [, Loved := (badge_excellence == "Loved by guests") + 0.1]
myhotels3 [, Top := (badge_excellence == "Top Hotel") + 0.1]

### Function to create R-square for 4 models
R2s <- function(x ,y){
  tmpy <- y [which (x > 0)]   #to eliminate log (0) 
  tmpx <- x [which (x > 0)]   #to eliminate log(0)
  logx <- log(tmpx)    #to eliminate log(0)
  sqx <- x ^2
  cubx <- x^3
  R2lin <- summary(lm(y~x))$r.squared
  R2log <- summary(lm(tmpy~logx))$r.squared   #to eliminate log(0)
  R2sqx <- summary(lm(y~x+sqx))$r.squared
  R2cub <- summary(lm(y~x+sqx+cubx))$r.squared
  return(c(R2lin, R2log,R2sqx, R2cub))
}

R2Table <- data.table (c("lev - lev lin", "lev - log", "Quadratic", "Qubic"), 
                          R2s (myhotels3 [, distance], myhotels3 [, price]), 
                          R2s (myhotels3 [, stars], myhotels3 [, price]),
                          R2s (myhotels3 [, Gold], myhotels3 [, price]),
                          R2s (myhotels3 [, Loved], myhotels3 [, price]),
                          R2s (myhotels3 [, Top], myhotels3 [, price]),
                          R2s (myhotels3 [, rating], myhotels3 [, price])
                          )
names(R2Table) <- c("RegType", "Distance", "Stars", "Gold", "Loved","Top", "Rating")
```

```{r Q224_results_of-R2Table}
pander(R2Table)
```


``` {r Q224_LevLogRegression}
regQ2_levlog <- lm(distance ~ lnprice, data=myhotels3)

#ggplot (Data, aes (x=logGDP, y = life )) + geom_point (size = 1.5) + 
#ggtitle("Q2. Level - Log linear regression") + labs(x = "Log GDP per capita [1000 USD]", y = "Life Expectancy [year]") + 
#geom_smooth (method = "lm")

ggplot (myhotels3, aes (x=lnprice, y = distance )) + geom_point (size = 1.5) + 
  ggtitle("Q2. Level - Log linear Regression") + labs(x = "lnprice", y = "Distance") +
  geom_line(data=myhotels3,aes(x=lnprice,y=predict(regQ2_levlog)),colour="blue",size = 1) + geom_smooth(method = 'lm')

regQ2_loglev <- lm(lnprice ~ distance, data=myhotels3)

#ggplot (Data, aes (x=logGDP, y = life )) + geom_point (size = 1.5) + 
#ggtitle("Q2. Level - Log linear regression") + labs(x = "Log GDP per capita [1000 USD]", y = "Life Expectancy [year]") + 
#geom_smooth (method = "lm")

ggplot (myhotels3, aes (x=distance, y = lnprice )) + geom_point (size = 1.5) + 
  ggtitle("Q2. Log - Level linear Regression") + labs(x = "Distance", y = "lnprice") +
  geom_line(data=myhotels3,aes(x=distance,y=predict(regQ2_loglev)),colour="blue",size = 1) + geom_smooth(method = 'lm')

summary (reg_levlog)
Data[,res_reg_levlog := residuals(reg_levlog)]
```


### <span style="color:blue"> 3. Estimate a multiple regression with all explanatory variables in the functional form you specified previously.  


```{r Q223 multiple_regression}
simplereg1 <- lm(lnprice ~ distance, data=myhotels3)
simplereg2 <- lm(lnprice ~ rating, data=myhotels3)
simplereg3 <- lm(lnprice ~ Gold, data=myhotels3)
simplereg4 <- lm(lnprice ~ Loved, data=myhotels3)
simplereg5 <- lm(lnprice ~ Top, data=myhotels3)

```

Doing the t-tests for each regression

```{r Q223 t-test}
coeftest(simplereg1, vcov=sandwich)
coeftest(simplereg2, vcov=sandwich)
coeftest(simplereg3, vcov=sandwich)
coeftest(simplereg4, vcov=sandwich)
coeftest(simplereg5, vcov=sandwich)

multireg3 <- lm(lnprice ~ distance + rating + Gold + Loved + Top + stars, data=myhotels3)
coeftest(multireg3, vcov=sandwich)
stargazer(list(simplereg1), list(simplereg2), list(simplereg3), list(multireg3), digits=2, out="hotels_reg2.tex")
```

### <span style="color:blue"> 4. Pick two slope coefficients, interpret them, and compute and interpret their 95% CI.

We have picked the slope of log price on distance... 

```{r Q224_slope1}
summary(simplereg1)
confint(simplereg1)
ggplot(data = myhotels3, aes(x=distance, y=lnprice)) +
  geom_point(size=0.5, colour="red") +
  geom_smooth(method="lm", colour="black")

```


...and the slope of log price on rating

```{r Q224_slope2}
summary(simplereg2)
confint(simplereg2)
ggplot(data = myhotels3, aes(x=rating, y=lnprice)) +
  geom_point(size=0.5, colour="red") +
  geom_smooth(method="lm", colour="black")

```
Interpretations.

price/distance:

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  4.60288    0.06798  67.712  < 2e-16 ***
distance    -0.20961    0.05224  -4.012 8.77e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.5565 on 182 degrees of freedom
Multiple R-squared:  0.08127,	Adjusted R-squared:  0.07622 
F-statistic:  16.1 on 1 and 182 DF,  p-value: 8.768e-05

95°% CI:
                2.5 %     97.5 %
(Intercept)  4.4687548  4.7370031
distance    -0.3126862 -0.1065369

Negative correlation, slope estimated -0.21.The t(p) value is close to zero, indicating a significant relationship between price and distance. R squared is low, meaning that solely the var. distance is hardly explaining the variance of price

price/rating:

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.32834    0.30550   4.348 2.28e-05 ***
rating       0.74840    0.07432  10.070  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.4653 on 182 degrees of freedom
Multiple R-squared:  0.3578,	Adjusted R-squared:  0.3543 
F-statistic: 101.4 on 1 and 182 DF,  p-value: < 2.2e-16

95°% CI
               2.5 %    97.5 %
(Intercept) 0.7255570 1.9311240
rating      0.6017687 0.8950387

Positive correlation, slope estimated +0.75.The t(p) value is close to zero here as well, indicating a significant relationship between price and rating. R squared is mutch higher then in price/distance regression (although still not high), the meaning is that the variance of rating gives a better explanation of the variance of price then we saw in case of price on distance. Lower Residual Standard Error of price/rating regression compared to price/ distance also confirming the stronger relation between variables, by showing a better fit of regression.

### <span style="color:blue"> 5. Describe your strategy to find the best deal. 

The aim would be to get the cheapest offer on a hotel that still meets certain described personal requirements. After describing the personal part, the goal is to find matching hotels with the most negative residuals. To do this we have to filter on variables of personal interest. We chose distance, stars and rating. We would like to stay in a 3 km range of city center in a 3 or more star hotel with a rating minimum of 4.1 (median). 

```{r Q224_strategy}
myhotels_Q5 <-myhotels2[accommodation_type=="Hotel"][stars>=3][rating>=4.1] #### itt hotel 8 helyett myhotels2 Imre verziója
summary(myhotels_Q5)
hotelresid <- lm(price ~ distance + rating + stars, data=myhotels_Q5)
resid(hotelresid)
# hotelresid[, l
```

### <span style="color:blue"> 6. List the hotels with the smallest (most negative) residuals. List their prices and other characteristics as well. Comment on the results. 

Problem 2.3

- Pick another city.

- Estimate the model of your choice in the previous exercise (ie the exact same dependent variables, same functional form) for another city of your choice. Discuss your finding.

test
