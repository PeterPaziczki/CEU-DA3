---
title: "Data Analysis 3 - Pattern Discovery and Regression Analysis 2017/2018 Fall"
author:
- name: Peter Paziczki
- name: Imre Boda
- name: Balazs Zankay
date: '2017 november 28'
output:
  html_document: default
  pdf_document: default
  word_document: default
---

<style>
body {
text-align: justify}
</style>

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

```{r load}
library(data.table)
library(ggplot2)
library(lspline)
library(pander)

#presentation parameters
theme_update(plot.title = element_text(hjust = 0.5, size = 12))

#Reading input files
GDP <- fread('GDP_per_capita_2014-Data.csv', encoding = 'UTF-8')
Life <- fread('Life_expectancy_at_birth_2014-Data.csv', encoding = 'UTF-8')
#Reading file to compare entries against country list
CountryList <- read.csv('https://www.searchify.ca/wp-content/uploads/2016/09/country-keyword-list.csv',fileEncoding="UTF-16LE")
```

# DA3 Assignment #2

## Problem2.1


### <span style="color:blue">Download cross-country data on life expectancy and GDP per capita. 
- “GDP per capita, PPP (constant)” and “Life expectancy at birth (total)”
</span>

We have downloaded both the above mentioned indicators for 2014, storing them in two separate csv files, GDP_per_capita_2014-Data.csv and Life_expectancy_at_birth_2014-Data.csv.

### <span style="color:blue"> Q1. 1. Delete unnecessary columns and save a csv file with three columns only: country name, life expectancy and GDP per capita. Keep countries with non-missing values for life expectancy and GDP per capita. Document what you do.
</span>

```{r Q1_basic}
# Joining the two tables by Country name column.

# Settin the ON clause as keys of the tables:
setkey(GDP, `Country Name`)
setkey(Life, `Country Name`)
# Inner joining the two tables, DT syntax
Data_raw <- Life[GDP, nomatch=0]

# Dropping the unnecessary columns, keeping only country name, life expectancy and GDP per capita columns
Data <- Data_raw[, -c(1,2,4,6:8)]
# renaming country name, life expectancy and GDP per capita columns for easier usage
names(Data) <- c("country", "life", "GDP")

# Dropping the obsevórvations where there is no country, and dropping countries where life expectancy and/or GPD are missing
Data <- Data[country!="",]
Data <- Data[life!="..", ]
Data <- Data[GDP!="..", ]
n <- Data_raw[`Country Name` != "",.N] # number of countries in the original data set
n_country <- nrow(CountryList)

# Both life expectancy and GDP per capita are character variables, they need to be converted into numeric variables.
Data <- Data[, lapply(.SD, as.numeric), by = country, .SDcols = c('life', 'GDP')]

# Shaping data
Data [, "GDP"] <- Data [, .(GDP = GDP/1000)]
# Taking the log of GDP per capita and sroting it in logGDP column.
Data [, logGDP := log(GDP)]
```

We have loaded both csv files and merged them by using a join like command. By using this special command we could make sure that relevant columns (Life expectancy and GDP) from the two tables were merged by matching the country name column, so the right values have been paired. The countries with missing life expectancy and/or GDP values have been dropped. We have `r Data[,.N]` entries of the `r n` left to analyze. Other unnecessary columns have also been dropped, such as Series Name, Series Code, Country Code. We have renamed the remaining columns as *country*, *life* and *GDP*, so it will be easier to type and use them. Life expectancy at birth is measure of how ling people people live on averahe in a specific country. GDP per capita stands for gross domestic product at purchasing power parity of a specific country, both at 2014 in our case. Finally we have divided GDP per capita by 1000 and took the log of it.

#### Data Cleaning
As the first step of data cleaining we have downloaded a csv file containing the list of `r n_country` countries in the world as of now. There were many entries in our data set that were no countries, so they were to be dropped.
We have aggregated lines in the data, that we have to remove as we only care about countries in the analysis.
We do this cleaning in two steps: first we check entries where the "country" is not inlcuded in the list of downloaded countries.
Then we manually check all of them, and collect those that are really not countries. (In the previous step some get classified as "non country" due to different writing in Data Bank and in the downloaded country list csv file). Once we have this collection of real non-countries, we remove all from the Data.

```{r Q1_Cleaning, results='hide'}
#there were countries where a country had different name in the original data and in the country list we have downloaded.
SuspectedGarbage <- Data[!country %in% CountryList[,1]]
Garbage <- SuspectedGarbage [ -c(1,2,4,5,6,7,8,11:15,20,21,28,29,32,38,39,40,41,50,51,52,61,64,65,66,68,71,75,76,77,80),]
#let's check that we put non-countries to garbage and we kept only countries
Garbage [, country]
SuspectedGarbage [ c(1,2,4,5,6,7,8,11:15,20,21,28,29,32,38,39,40,41,50,51,52,61,64,65,66,68,71,75,76,77,80),country]
#Removing all non country entries from the database and keeping only countries
Data <- Data[!country %in% Garbage [,country]]
```

The `r Garbage[,.N]` entries have been dropped because of being marked as non-countries. After data cleaning we have `r Data[,.N]` countries to investigate.

Please find summary statistics of life variable below:

```{r Q1_LifeSummary}
pander(summary(Data[,life]))
ggplot (Data, aes(life)) + geom_histogram(binwidth = 1) + ggtitle(labs(title = "Q1. Histogram of life variable", x = "Life expectancy at birth [years]"))
```

```{r Q1_min_max_life_countries}
pander(Data [life == Data [,min(life)] | life == Data [,max(life)],])
```

Life expactancy is the highest in Hong Kong SAR, China, and the lowest in the Central African Republic, `r max(Data$life)` and `r min(Data$life)` respectively. The difference between the minimum and maximum values is quite large. Mean is close to the median, but life expectancy variable does not have a symmetric distribution, it rather seems to be skewed to the left.

Please find summary statistics of GDP per capita variable below:

```{r Q1_GDPSummary}
pander(summary(Data[,GDP]))
ggplot (Data, aes(GDP)) + geom_histogram ( binwidth=6) + ggtitle(labs(title = "Q1. Histogram of GDP variable", x = "GDP per capita [1000 USD]"))
```

```{r Q1_min_max_GDP_countries}
pander(Data [GDP == Data [,min(GDP)] | GDP == Data [,max(GDP)],])
```

GDP follows a log normal like distribution with a long right tail, it is tipically a clear sign that we are better to take the logarithm of the variable. GDP is the highest in Macao SAR, China, and the lowest in the Central African Republic, `r max(Data$GDP)` and `r min(Data$GDP)` respectively. In this case the difference between the minimum and maximum value is very significant.

Please find summary statistics of logGDP variable below:

```{r Q1_logGDP}
pander(summary(Data[,logGDP]))
ggplot(Data, aes(logGDP)) + geom_histogram (binwidth=0.5) + ggtitle(labs(title = "Q1. Histogram of logGDP variable", x = "Log GDP per capita [1000 USD]"))
```

The histogram of logGDP per capita has a more symmetric distribution then the GDP per capita variable. The spread is also big in this case.

### <span style="color:blue"> Q2. Estimate a lowess regression of life expectancy on ln gdp per capita. Estimate a linear regression of life expectancy on GDP per capita that best captures the nonlinearity you found (life expectancy on a piecewise linear spline or a polynomial in the explanatory variable). Argue for your choice. Report the coefficient estimates as well as their confidence interval, interpret and visualize the results.
</span>

In the following sections we go deeper in understanding our data.

First, let's have a look at the scatterplot with GDP per capita on the x axis and life expectancy at birth on the y axis.

```{r Q2_scatterplot_GDP}
# Creating a scatterplot to have a quick look at the data we have:
ggplot(Data, aes(x = GDP, y = life)) + geom_point() +
  ggtitle ("Q2. GDP - Life expectancy") + labs(x="GDP per capita, PPP [USD]",y="Life expectancy at birth [years]")
```

Many countries have a low level of GDP per capita, thus there are many observations close to the y axis. As we stated above, GDP per capita is strongly skewed to the right, having logGDP on the x axis might give a fit.

```{r Q2_scatterplot_logGDP}
ggplot(Data, aes(x = logGDP, y = life)) + geom_point () +
  ggtitle ("Q2. Log GDP - Life expectancy") + labs(x="Log GDP per capita, PPP [USD]",y="Life expectancy at birth [years]")
```

The above graphs show that we are probably on the right track when trying to find relationship between log GDP and Life Expectancy, rather than GDP and Life Expectancy.

We took the log of GDP per capita, as we are interested in relative % changes instead of absolute terms. Lowess produces a smooth curve, that allows us to capture non-linear patterns. (The con of lowess is that it does not provide a formula to describe the relationship between life expectancy and GDP. What lowess does is that it provides an expected y value for every x values and for x values in-between resulting in a graph that we can use in qualitative analysis.
In this particular case we have log GDP per capita on the x axis and life expectancy on the y axis.

```{r Q2_lowessGraph}
# Estimating a lowess non-parametric regression on the data set.
reg_loess <- loess (life ~ logGDP, Data)
ggplot(data = Data, aes(x=logGDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Lowess regression") + labs(x="Log GDP per capita, PPP [USD]",y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_loess)),colour="blue",size = 1)
summary (reg_loess)
```

We can see that the graph has a positive slope in general. At the right end of the curve it gets a little flatter, but remains still positive. So we can assumte that there is some sort of positive correlation between these two variables. A possible interpretation at this point can be that there is a general positive relationship between GDP per capita and life expectancy. The higher the GDP per capita is in a country, the longer the life expectancy is on average.

#### Level - Log Linear Regression
``` {r Q2_LevLogRegression}
reg_levlog <- lm(life ~ logGDP, data=Data)

#ggplot (Data, aes (x=logGDP, y = life )) + geom_point (size = 1.5) + 
#ggtitle("Q2. Level - Log linear regression") + labs(x = "Log GDP per capita [1000 USD]", y = "Life Expectancy [year]") + 
#geom_smooth (method = "lm")

ggplot (Data, aes (x=logGDP, y = life )) + geom_point (size = 1.5) + 
ggtitle("Q2. Level - Log linear Regression") + labs(x = "Log GDP per capita [1000 USD]", y = "Life Expectancy [year]") + 
geom_line(data=Data,aes(x=logGDP,y=predict(reg_levlog)),colour="blue",size = 1) + geom_smooth(method = 'lm')

summary (reg_levlog)
Data[,res_reg_levlog := residuals(reg_levlog)]
```

We seem to have rather small residual errors and pretty good R-squared, 66.5%, confirming the relationship between logGDP and Life Expectancy.
The intercept estimate is 58.9839, which is hard to interpret in real life for practical reasons, it means that in a country with 0 logGDP the life expectancy at birth would be approx. 59 years on average. The slope estimate is 5.4607 which means that life expectancy is 0.54607 years higher on average in countries with 10% higher GDP per capita. The slope estimate is significant at 0.1%, with other words, life expectancy and log GDP per capita are correlated at a 99.9 

Equatorial Guinea has the greatest negative residual, the life expectancy is `r abs(min(residuals(reg_levlog)))` lower that one could expect based on the regression. The next two countries with greatest negative residuals are Nigeria and Swaziland, -15.9 and -14.3 years respectively. The highest positive residuals are Vietnam, Solomin Islands and Nicaragua, the residuals are over 7 years, meaning that people live more than 7 years longer on average, as one could expect based on the GDP per capita.

The residuals of the seven countries with highest GDP per capita are all negative, which is quite unexpected. This is something that we are going to consider when creating piecewise linear splines.


#### Log - Log regression
``` {r Q2_Log-Log}
# LOG-LOG REGRESSION
reg_loglog <- lm(log(life) ~ logGDP, data=Data)
ggplot(data = Data, aes(x=logGDP, y=log(life))) +  geom_point(size=1.5) +
  ggtitle ("Q2. Log-Log linear regression") +  
  labs(x="Log - GDP per capita, PPP [USD]", y="Log - Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_loglog)),colour="blue",size = 1) + geom_smooth(method = 'lm')
summary(reg_loglog)
```  

R-squared is slightly lower than in the previous case, but it is not significant at all, but this regression is more difficult to interpret. It can be interpreted as life expectency is 0.078776% higher on average for observations with 1% higher GDP per capita. 


#### Lev - Lev regression

Though the scatterplots above suggested that the level - level linear correlation probaly is not the best model, just for the sake of completeness let's see a level-level linear regression model.
``` {r Q2_Lev-Lev}
# LOG-LOG REGRESSION
reg_levlev <- lm(life ~ GDP, data=Data)
ggplot(data = Data, aes(x=GDP, y=life)) +  geom_point(size=1.5) +
  ggtitle ("Q2. Level - Level linear regression") +  
  labs(x="GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=GDP,y=predict(reg_levlev)),colour="blue",size = 1) + geom_smooth(method = 'lm')
summary(reg_levlev)
```  

Both R-squared and the plot confirms our assumption that there are much better models that the simple level - level linear regression. This plot could obviously not capture the relationship as good as the previous ones.


#### Level - Level Quadratic regression

``` {r Q2_Level-Level_QuadraticRegression}
# Estimating a quadratic regression on GDP and life expectancy:
Data[, GDP_sq := GDP^2]
reg_quad_levlev <- lm(life ~ GDP + GDP_sq, data=Data)

ggplot(Data, aes(x=GDP, y=life)) +  geom_point(size=1.5) + 
  ggtitle ("Q2. Quadratic regression") +  
  labs(x="GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=GDP,y=predict(reg_quad_levlev)),colour="blue",size = 1)

summary(reg_quad_levlev)
```

R-squared is lower and residual error is higher than before, indicating that it might not be as good model as the previous one is. Frankly, probably there is nothing to justify that life expectancy would peek at `r round (0.58 / 2 / 0.0039)` kUSD GDP per capita, and very rich countries would suffer. The reasonably small error rate to this model is likely attributable to the fact that we have very few very rich countries (hence, small number of observations on this end.)


#### Level - Log Quadratic regression
``` {r Q2_Level_Log_QuadraticRegression}
# Estimating a quadratic regression on log GDP pre capita and life expectancy:
Data[, logGDP_sq := logGDP^2]
reg_quad_levlog <- lm(life ~ logGDP + logGDP_sq, data=Data)

ggplot(Data, aes(x=logGDP, y=life)) +  geom_point(size=1.5) + 
  ggtitle ("Q2. Quadratic regression") +  
  labs(x="log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_quad_levlog)),colour="blue",size = 1)

summary(reg_quad_levlog)
```


#### Level - Level Cubic Regression
``` {r Q2_Level_Level_CubicRegression}
Data[,GDP_cu := GDP^3]
reg_cub_levlev <- lm(life ~ GDP + GDP_sq + GDP_cu, data=Data)

ggplot(data = Data, aes(x=GDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Cubic regression") +  
  labs(x="GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=GDP,y=predict(reg_cub_levlev)),colour="blue",size = 1)

summary(reg_cub_levlev)
```


#### Level - Log Cubic Regression
``` {r Q2_Level_Log_CubicRegression}
Data[,logGDP_cu := logGDP^3]
reg_cub_levlog <- lm(life ~ logGDP + logGDP_sq + logGDP_cu, data=Data)

ggplot(data = Data, aes(x=logGDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Cubic regression") +  
  labs(x="log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_cub_levlog)),colour="blue",size = 1)

summary(reg_cub_levlog)
```


#### Piecewise Linear Spline

In the lowess diagram we have seen that something slope is changing at about x = 4. In addition to that in when having a log level regression We have uncovered that the seven countries with highest GDP per capita all have negative residuals, in all countries the life expectancy was below the regression line. Considering these observations we select the knot accordingly and build the PLS model accordingly.

``` {r Q2_PLS}

# PIECEWISE LINEAR SPLINE IN LEVEL-LOG REGRESSION
knots <- c(4)
reg_PLS <- lm(life ~ lspline(logGDP,knots), data=Data)

ggplot(data = Data, aes(x=logGDP, y=life)) +
  geom_point(size=1.5) +
  ggtitle ("Q2. Piecewise Linear Spline") +
  labs(x="Log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_PLS)),colour="blue",size = 1) +
  geom_vline(xintercept =knots,colour="red")

summary (reg_PLS)
```

The R-squared of the regression is 67.28%. It is bit higher than the R-squared of the level log regression. It is not surprising because with two lines with possibly two different slopes we have to provide at least as good fit as with one linear. The slope of the first linear is 5.6889, shows positive relation between log GDP per capita and life expectancy, and it is significant at 0.1%. A slope of 5.6889 means, that below approximately 54,600 USD (log GDP per capita = 4) the life expectancy is 0.56889 years higher on average for countries with 10% higher GDP erp capita. The second linear beyond log GDP per capita 4 has a negative slope and it has captured that we have observed when doing a lowess regression. The slope estimate is -1.6650, but it is not significant at even 10%. This second short linear provides a better fit for 9 countries, meaning that the life expectancy is 0.16650 years lower on average in countries with 10% higher GDP per capita.


#### Choosing the best model and evaluating it

After the investigation we can see that the level - log regression has best captured the relatiom between life expectancy and GDP per capita, with logarithm of GDP PPP as the explanatory variable.

```{r Q2_Model selection}

RSq <- data.table (c("Level - Log  :  ",
                     "Log - Log    :  ", 
                     "Level - Level:  ", 
                     "Quadratic Level - Level   :  ", 
                     "Quadratic Level -Log",
                     "Cubic Level - Level        :  ", 
                     "Cubic Level - Log        :  ", 
                     "PLS (spline) :  "), 
                   c(summary(reg_levlog)$r.squared,
                     summary(reg_loglog)$r.squared,
                     summary(reg_levlev)$r.squared,
                     summary(reg_quad_levlev)$r.squared,
                     summary(reg_quad_levlog)$r.squared,
                     summary(reg_cub_levlev)$r.squared,
                     summary(reg_cub_levlog)$r.squared,
                     summary(reg_PLS)$r.squared
                     ))
pander(RSq)
```

Quadratic and cubic polynomial regression also captured that change in the slope for countries with the highest GDP per capita, but level - log regression and linear spline were the ones that best captured the variance in y.

``` {r Q2_Coefficients,for studying purposes, results='hide'}
# Coefficient calculations, confidence interval
# for studying purposes we were computing it by hand as well

### x = logGDP, y = life

## easy way:
coef (reg_levlog)
confint (reg_levlog)

## manual
Beta_estimate <- cov (Data [,logGDP], Data[,life]) / var (Data [, logGDP]) # cov (x,y) / var (x)
Alpha_estimate <- Data [, mean(life)] - Beta_estimate * Data [,mean (logGDP)]  # mean (y) - beta * mean (x)
Beta_estimate
Alpha_estimate
# sd of Residual Error calculation in 3 ways
sdResidErr1 <- sd (Data [, life - (Alpha_estimate + Beta_estimate * logGDP)]) #R built in sd function
sdResidErr2 <- Data [, (sum((life - (Alpha_estimate + Beta_estimate * logGDP))^2) / (.N-1))^0.5] #formula, n-1
sdResidErr3 <- Data [, (sum((life - (Alpha_estimate + Beta_estimate * logGDP))^2) / (.N-2))^0.5] #formula, n-2

sdResidErr1
sdResidErr2
sdResidErr3
# interpretation: sdResidErr1 and sdResidErr2 are the same, but different from tha value that we saw in summary (reg_levlog) above. The reason is that summary (reg_levlog) calculated with df = N-2, as it was also mentioned in that printout. In the below confidence interval calculation we will use sdResidErr1
Conf95 <- c(Beta_estimate - 1.96 * sdResidErr1 / Data [,sd(logGDP)]  / (nrow (Data)-1) ^0.5, Beta_estimate + 1.96 * sdResidErr1 / Data [,sd(logGDP)]  / (nrow (Data) -1) ^0.5)
Conf95

# Coefficients and Confidence interval at 95% have been calculated with built-in R functions as well as with statistical formulas. It is worth noting that Alpha and Beta estimates are the same that we got earlier, and examined when printed the summary of reg_levlog model.
```


### <span style="color:blue"> 3. Estimate a weighted regression (weight=population). Compare results to what we saw in class. 
</span>

In order to do it, first we need to enhance our data with population. For that we downloaded 2014 population data form the same "World Development Indicators" website.

``` {r Q3_Population, results='hide'}
## Download and clean population data
PopData <- fread ('Population_2014.csv')
str (PopData)
PopData <- PopData [PopData [[2]] == "SP.POP.TOTL"]   #filtering to Total Population only (where data in column 2 = "SP.POP.TOTL")
PopData <- PopData [, -c(1,2,4)]
names(PopData) <- c("Country", "Population")
PopData <- PopData [, .(Population = as.numeric(Population)), by = Country]
PopData <- PopData [!is.na(Population),]
str (PopData)

## Enhance Data with population info
setkey(PopData, `Country`)
setkey(Data, `country`)
Data2 <- Data[PopData, nomatch=0] #inner join DT syntax
str (Data2)
# sanity check (values)
Data2 [is.na(Population),]
Data2 [country == "Hungary",]
Data2 [country == "United States",]
# Cool, we got data filled in for all
```

``` {r Q3_weighted model}
reg_weight<- lm (life ~ logGDP, weight = Population, data = Data2)

ggplot (Data2, aes (x = logGDP, y = life, size = Population)) + 
  geom_point(shape = 21, fill = "#009E73", alpha = 0.5, show.legend = FALSE) + 
  scale_size_continuous(range = c(1, 15)) +
  ggtitle ("Q3. Weighted Lev-Log Regression") +
  labs(x="Log GDP per capita, PPP [USD]", y="Life expectancy at birth [years]") +
  geom_line(data=Data,aes(x=logGDP,y=predict(reg_weight)),colour="blue",size = 1)

summary (reg_weight)
```

When doing a level-log regression without considering the population, the slope estimate was 5.4607, it is now 5.8169, slightly higher. China and India have the highest population in the world and they are very close to the regression line and are approximately in the middle of the log GDP per capita sitribution, they don't alter the slope significantly. We can say that after considering the population as weight, life expectancy is 0.58169 years higher on average in countries with 10% higher GDP per capita.


##<span style="color:blue"> Problem 2.2

Download hotels_all_nov21.csv. Pick a city. Consider hotels and hostels. Consider all with at least 2 stars. You have 6 tasks (1p each). 
The goal of the exercise is to use information you have in your data to find a shortlist of five hotels and/or hostels that are good candidates for a good deal. You have to estimate a regression of prices (or log prices) on the other variables of your choice. You have to document your analysis and print the shortlist. 
</span>

``` {r Q22_basic, results='hide'}
#loading necessry libraries
#install.packages("haven")
library(haven)
#install.packages("dplyr")
library(dplyr)
library(lmtest)
library(sandwich)
library(stargazer)

# loading the hotels_all_nov21.csv file to a data table object
hotel_raw <- fread('hotels_all_nov21.csv', encoding = 'UTF-8')

str(hotel_raw)
# checking each categories, setting our choices
City <- "Athens" # city of our choice
MIN_STARS <-2 # minimum number of stars
MAX_DIST <- 6.25

hotel_min2stars <-hotel_raw[city == City][accommodation_type=="Hotel"][stars>=MIN_STARS]
hostel_min2stars <-hotel_raw[city == City][accommodation_type=="Hostel"][stars>=MIN_STARS]
str(hotel_min2stars)
str(hostel_min2stars)

#merging the hotels and hostels with at least 2 stars
hotel3 <-merge(hotel_min2stars, hostel_min2stars, all=TRUE)

# taking another approach, this time without separate checking
hotel4 <- hotel_raw[city==City & stars >=MIN_STARS & accommodation_type %in% c("Hotel","Hostel")]

# checking if Hotel and Hostel data are not fragmented in dataset due to improper typing
table(hotel3$accommodation_type)

# dropping unnecessary columns
# now let's keep just the columns of selected variables
hotel4 <- hotel4[, .(name, distance, stars, badge_excellence, rating, rating_reviewcount, price, address)]
# distance, price, stars, rating, badge excellence and rating reviewcount variables have been selected for further analysis.

# checking if there is missing data in any of the selected columns
hotel4[is.na (distance) | is.na(price) | is.na(stars) | is.na(rating) | is.na(badge_excellence) | is.na(rating_reviewcount),]

# dropping lines with missing data
hotel5 <- hotel4[!(is.na (distance) | is.na(price) | is.na(stars) | is.na(rating) | is.na(badge_excellence) | is.na(rating_reviewcount)),]
data_missing <- hotel4[(is.na (distance) | is.na(price) | is.na(stars) | is.na(rating) | is.na(badge_excellence) | is.na(rating_reviewcount)),.N]
str(hotel5)

# checking if there is dupplication by name or address
pander(hotel5[duplicated(hotel5),])
hotel5[!duplicated(hotel5),]

hotel5 [,.N] - hotel5 [,length(unique (address))]
hotel5 [,.N] - hotel5 [,length(unique (name)) ]
hotel5 [,.(name, .N), by = address][N>1,] # hotels with the same address
hotel5 [,.(address, .N), by = name][N>1,] # duplicates by name

# dropping duplications
hotel6 <-hotel5 %>% distinct(name, .keep_all = TRUE)
hotel7 <-hotel6 %>% distinct(address, .keep_all = TRUE)
hotel7$address <- NULL # address is not needed anymore, dropping it
str(hotel7)
n_duplicate <- hotel5[,.N] - hotel7[,.N]

# lets take hotels maximum 1 hour walk (6.25 km) from city center (you may prefer walking due to traffic jams, etc - but not too much walking...)
hotel8 <- hotel7[distance <= MAX_DIST, ]
str(hotel8)
```

First we have loaded the file and picked a city randomly (happened to be Athens). We have filtered down the data to accommodation types 'Hostel' and 'Hotel' with at least 2 stars. After narrowing down the data we have done further data cleaning. We are interested in a few variables, such as distance from the city center, price, number of stars, rating, rating viewcounts, different badges of excellence the hotel or hostel might have and distance, all other variables are excluded. First we have dropped `r data_missing` observations that miss parameters we might be interested in. Then we have dropped `r n_duplicate` duplicates, there were hotels with the same address, and a few hotels had more addresses, these have been sorted out. We wanted to limit our investigation to hotels and hostels that are not futher than 6.25km, which is approximately a one hour walk.

```{r}
# checking types of badge excellence
table(hotel8$badge_excellence)
# as this variable is obviously categorical we transform it to binary variable
hotel8[, Gold := (badge_excellence == "Gold Award 2017")+1]
hotel8[, Loved := (badge_excellence == "Loved by guests")+1]
hotel8[, Top := (badge_excellence == "Top Hotel")+1]

Gold <- as.numeric(hotel8$Gold)-1
Loved <- as.numeric(hotel8$Loved)-1
Top <- as.numeric(hotel8$Top)-1
list(Top)
summary(hotel8)
```

Next step is to filter extreme values.
- remove those that are considered to be outside of Athens (apparently all those that are further away than the hotel with the highest distance in Piraeuswhich means that we conside everything that is further away then Piraeus as suburb not Athens).
- we do not drop any hotel due to high price.

``` {r Q2_extremevalues}
max_in <- myhotels1 [city_actual == "Piraeus", max (distance)]
myhotels2 <- myhotels1[distance <= max_in, ]
myhotels2 [price >200,]  #checking who the very expensive ones are. After analyzing on web, we found tht these all are "normal" high priced hotels, we keep those.
myhotels3 <- myhotels2 [, .(distance, stars, badge_excellence, rating, rating_reviewcount, price)] #remove not needed data

```

### <span style="color:blue"> 2.2.1. Pick a set of variables. Describe all variables used in the analysis.
</span>

!!! I guess these are distance, stars, rating, badge_excellence, rating_reviewcount, price
!!!BLA-BLA-BL

Now we need to describe all the variables we have. Let's have a scatterplot first with distance on the x axis and price on the y axis.

```{r Q22_statistics_of_variables}
ggplot(hotel8, aes(x=distance, y=price)) + geom_point(shape = 1) + ggtitle(labs(title = "Q2. Scatterplot of price on distance", x = "Distance from the city center [km]", y = "Price [EUR]"))

# SUMMARY STATISTICS ON PRICE
qplot(hotel8$price, geom="histogram", binwidth=20) + theme_bw() + ggtitle(labs(title = "Q2. Histogram of price variable", x = "Price [EUR]"))
price_stat<-hotel8[,.(mean_price = mean(price) , sd_price = sd(price), 
                      min_price = min(price) , max_price = max(price), 
                      p50=quantile(price,.50), p95=quantile(price,.95), n=.N )]
pander(price_stat)
```

BLA BLA

```{r}
# SUMMARY STATISTICS ON DISTANCE
qplot(hotel8$distance, geom="histogram", binwidth=0.4) + theme_bw() + ggtitle(labs(title = "Q2. Histogram of distance variable", x = "Distance from the city center [km]"))

distance_stat <-hotel8[,.(mean_dist = mean(distance) , sd_dist = sd(distance),
                          min_dist = min(distance) , max_dist = max(distance),
                          p50 = quantile(distance,.50), p95 = quantile(distance,.95), n=.N )]
pander(distance_stat)
```

### <span style="color:blue"> 2.2.2. Investigate potential nonlinearity of each explanatory variable in simple regressions of the dependent variable. Decide on a parametric functional form for each.

Amiket szerintem érdemes megnézni:
lev-lev
lev-log
quadratic
cubic

``` {r Q2_nonlinears}
### Function to create R-square for 4 models
R2s <- function(x ,y){
  tmpy <- y [which (x > 0)]   #to eliminate log (0) 
  tmpx <- x [which (x > 0)]   #to eliminate log(0)
  logx <- log(tmpx)    #to eliminate log(0)
  sqx <- x ^2
  cubx <- x^3
  R2lin <- summary(lm(y~x))$r.squared
  R2log <- summary(lm(tmpy~logx))$r.squared   #to eliminate log(0)
  R2sqx <- summary(lm(y~x+sqx))$r.squared
  R2cub <- summary(lm(y~x+sqx+cubx))$r.squared
  return(c(R2lin, R2log,R2sqx, R2cub))
}

R2Table <- data.table (c("lev - lev lin", "lev - log", "Quadratic", "Qubic"), 
                          R2s (myhotels3 [, distance], myhotels3 [, price]), 
                          R2s (myhotels3 [, stars], myhotels3 [, price]),
                          R2s (myhotels3 [, Gold], myhotels3 [, price]),
                          R2s (myhotels3 [, Loved], myhotels3 [, price]),
                          R2s (myhotels3 [, Top], myhotels3 [, price]),
                          R2s (myhotels3 [, rating], myhotels3 [, price])
                          )
names(R2Table) <- c("RegType", "Distance", "Stars", "Gold", "Loved","Top", "Rating")
R2Table


# =====
  
  
  
```{r}
R2s <- function(x ,y){
  tmpy <- y [which (x > 0)]   #to eliminate log (0) 
  tmpx <- x [which (x > 0)]   #to eliminate log(0)
  logx <- log(tmpx)    #to eliminate log(0)
  sqx <- x ^2
  cubx <- x^3
  R2lin <- summary(lm(y~x))$r.squared
  R2log <- summary(lm(tmpy~logx))$r.squared   #to eliminate log(0)
  R2sqx <- summary(lm(y~x+sqx))$r.squared
  R2cub <- summary(lm(y~x+sqx+cubx))$r.squared
  return(c(R2lin, R2log,R2sqx, R2cub))
}

R2Table <- data.table (c("lev - lev lin", "lev - log", "Quadratic", "Qubic"), 
                       R2s (hotel9[, distance], hotel9 [, price]), 
                       R2s (hotel9 [, stars], hotel9 [, price]),
                       R2s (hotel9 [, Gold], hotel9 [, price]),
                       R2s (hotel9 [, Loved], hotel9 [, price]),
                       R2s (hotel9 [, Top], hotel9 [, price]),
                       R2s (hotel9 [, rating], hotel9 [, price]))
names(R2Table) <- c("RegType", "Distance", "Stars", "Gold", "Loved","Top", "Rating")
R2Table
summary(R2Table)

```
#### itt átváltható az Imre által használt  myhotel3 a hotel9 névre, de Imre kihagyta a hotel nevét az ő táblájából.
```

3. Estimate a multiple regression with all explanatory variables in the functional form you specified previously.  

4. Pick two slope coefficients, interpret them, and compute and interpret their 95% CI. 

5. Describe your strategy to find the best deal. 

6. List the hotels with the smallest (most negative) residuals. List their prices and other characteristics as well. Comment on the results. 

Problem 2.3

- Pick another city.

- Estimate the model of your choice in the previous exercise (ie the exact same dependent variables, same functional form) for another city of your choice. Discuss your finding.

test
